{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "556dc471-9c0a-4373-a2ca-1564e4055ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f876a89-161a-462a-9e38-47eeb4789cbb",
   "metadata": {},
   "source": [
    "# 1 - Importando dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea87ba7-9383-4081-8828-ddc36bac3322",
   "metadata": {},
   "source": [
    "## 1.1 - DataFrame com o schema definido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c4a8067-2462-4370-9528-bee074a15712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo o schema baseado nos dados a serem importados\n",
    "arqschema = \"\"\"id INT, nome STRING, \n",
    "               status STRING, \n",
    "               cidade STRING, \n",
    "               vendas INT, \n",
    "               data STRING\"\"\"\n",
    "# Nessa caso iremos indicar a coluna data como STRING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7c56659-8731-4b56-8a79-18593f0ef2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+------+-------------+------+----------+\n",
      "| id|               nome|status|       cidade|vendas|      data|\n",
      "+---+-------------------+------+-------------+------+----------+\n",
      "|  1|   Carminda Pestana| Ativo|  Santa Maria|    23|2020-08-11|\n",
      "|  2|    Deolinda Vilela| Ativo|Novo Hamburgo|    34|2020-03-05|\n",
      "|  3|   Emídio Dornelles| Ativo| Porto Alegre|    34|2020-02-05|\n",
      "|  4|Felisbela Dornelles| Ativo| Porto Alegre|    36|2020-02-05|\n",
      "|  5|     Graça Ornellas| Ativo| Porto Alegre|    12|2020-02-05|\n",
      "|  6|   Matilde Rebouças| Ativo| Porto Alegre|    22|2019-01-05|\n",
      "|  7|    Noêmia   Orriça| Ativo|  Santa Maria|    45|2019-10-05|\n",
      "|  8|      Roque Vásquez| Ativo| Porto Alegre|    65|2020-03-05|\n",
      "|  9|      Uriel Queiroz| Ativo| Porto Alegre|    54|2018-05-05|\n",
      "| 10|   Viviana Sequeira| Ativo| Porto Alegre|     0|2020-09-05|\n",
      "+---+-------------------+------+-------------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importando um arquivo csv\n",
    "despachantes = spark.read.csv(\"./data/despachantes.csv\", header = False, schema = arqschema)\n",
    "despachantes.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf7e19d-6bd6-4c68-b01c-75cbf2875962",
   "metadata": {},
   "source": [
    "## 1.2 - DataFrame na qual o schema é inferido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9d59c24-9049-4a16-8615-aa38251f4ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+-----+-------------+---+-------------------+\n",
      "|_c0|                _c1|  _c2|          _c3|_c4|                _c5|\n",
      "+---+-------------------+-----+-------------+---+-------------------+\n",
      "|  1|   Carminda Pestana|Ativo|  Santa Maria| 23|2020-08-11 00:00:00|\n",
      "|  2|    Deolinda Vilela|Ativo|Novo Hamburgo| 34|2020-03-05 00:00:00|\n",
      "|  3|   Emídio Dornelles|Ativo| Porto Alegre| 34|2020-02-05 00:00:00|\n",
      "|  4|Felisbela Dornelles|Ativo| Porto Alegre| 36|2020-02-05 00:00:00|\n",
      "|  5|     Graça Ornellas|Ativo| Porto Alegre| 12|2020-02-05 00:00:00|\n",
      "|  6|   Matilde Rebouças|Ativo| Porto Alegre| 22|2019-01-05 00:00:00|\n",
      "|  7|    Noêmia   Orriça|Ativo|  Santa Maria| 45|2019-10-05 00:00:00|\n",
      "|  8|      Roque Vásquez|Ativo| Porto Alegre| 65|2020-03-05 00:00:00|\n",
      "|  9|      Uriel Queiroz|Ativo| Porto Alegre| 54|2018-05-05 00:00:00|\n",
      "| 10|   Viviana Sequeira|Ativo| Porto Alegre|  0|2020-09-05 00:00:00|\n",
      "+---+-------------------+-----+-------------+---+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Neste caso utilizarei o método read.load e informar o formato como csv.\n",
    "desp_autoschema = spark.read.load(\"./data/despachantes.csv\", \n",
    "                                  header = False, \n",
    "                                  format=\"csv\", \n",
    "                                  sep=\",\",\n",
    "                                 inferSchema = True)\n",
    "desp_autoschema.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3505e7f5-dec8-4eb1-aa61-b35720d57a31",
   "metadata": {},
   "source": [
    "## 1.3 - Comparando os schemas dos DataFrames acima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7dc01e62-5610-4a5c-8b1e-943e37eb26c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('id', IntegerType(), True), StructField('nome', StringType(), True), StructField('status', StringType(), True), StructField('cidade', StringType(), True), StructField('vendas', IntegerType(), True), StructField('data', StringType(), True)])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "despachantes.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fb385bb-40df-4dd8-9b1a-7068b2a9506a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('_c0', IntegerType(), True), StructField('_c1', StringType(), True), StructField('_c2', StringType(), True), StructField('_c3', StringType(), True), StructField('_c4', IntegerType(), True), StructField('_c5', TimestampType(), True)])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desp_autoschema.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1694e7b6-7b93-4f65-b250-6ea564e85a28",
   "metadata": {},
   "source": [
    "No caso em que o schema foi inferido, na coluna data foi automaticamente convertido para o tipo timestampType()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b864566-a8c7-4c16-964a-24c4cbf6e2c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
